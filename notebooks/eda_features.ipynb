{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA: data, features, autocorrelation\n",
        "\n",
        "This notebook is a lightweight exploratory analysis for the competition dataset.\n",
        "It focuses on:\n",
        "- schema sanity + basic stats\n",
        "- target distributions (including `abs(y)` weighting intuition)\n",
        "- per-feature correlation with targets\n",
        "- autocorrelation / cross-correlation (lags) inside sequences\n",
        "\n",
        "Notes:\n",
        "- `train.parquet` is large; most analyses here sample sequences.\n",
        "- We use `valid.parquet` by default because it's smaller and usually sufficient for EDA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "80c549d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train exists: True ../datasets/train.parquet\n",
            "valid exists: True ../datasets/valid.parquet\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional (nice to have)\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    sns.set_theme(style='whitegrid')\n",
        "except Exception:\n",
        "    sns = None\n",
        "\n",
        "pd.set_option('display.max_columns', 200)\n",
        "np.set_printoptions(suppress=True, precision=4)\n",
        "\n",
        "DATA_DIR = Path('..') / 'datasets'\n",
        "TRAIN_PATH = DATA_DIR / 'train.parquet'\n",
        "VALID_PATH = DATA_DIR / 'valid.parquet'\n",
        "\n",
        "print('train exists:', TRAIN_PATH.exists(), TRAIN_PATH)\n",
        "print('valid exists:', VALID_PATH.exists(), VALID_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "095e7130",
      "metadata": {},
      "source": [
        "## 1) Schema + quick sanity\n",
        "We expect: 3 meta cols + 32 features + 2 targets = 37 columns.\n",
        "\n",
        "- meta: `seq_ix`, `step_in_seq`, `need_prediction`\n",
        "- features: `p0..p11`, `v0..v11`, `dp0..dp3`, `dv0..dv3`\n",
        "- targets: `t0`, `t1`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "77f8fb2d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path: ../datasets/valid.parquet\n",
            "rows: 1444000\n",
            "row_groups: 2\n",
            "ncols: 37\n",
            "columns: ['seq_ix', 'step_in_seq', 'need_prediction', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6'] ...\n",
            "path: ../datasets/train.parquet\n",
            "rows: 10721000\n",
            "row_groups: 11\n",
            "ncols: 37\n",
            "columns: ['seq_ix', 'step_in_seq', 'need_prediction', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6'] ...\n"
          ]
        }
      ],
      "source": [
        "import pyarrow.parquet as pq\n",
        "\n",
        "def parquet_info(path: Path):\n",
        "    pf = pq.ParquetFile(path)\n",
        "    schema = pf.schema_arrow\n",
        "    print('path:', path)\n",
        "    print('rows:', pf.metadata.num_rows)\n",
        "    print('row_groups:', pf.metadata.num_row_groups)\n",
        "    print('ncols:', len(schema.names))\n",
        "    print('columns:', schema.names[:10], '...')\n",
        "    return schema.names\n",
        "\n",
        "cols_valid = parquet_info(VALID_PATH)\n",
        "cols_train = parquet_info(TRAIN_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "118e0c01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "missing: []\n",
            "extra: []\n",
            "n_expected: 37\n"
          ]
        }
      ],
      "source": [
        "FEATURE_NAMES = [\n",
        "    *[f'p{i}' for i in range(12)],\n",
        "    *[f'v{i}' for i in range(12)],\n",
        "    *[f'dp{i}' for i in range(4)],\n",
        "    *[f'dv{i}' for i in range(4)],\n",
        "]\n",
        "TARGET_NAMES = ['t0', 't1']\n",
        "META = ['seq_ix', 'step_in_seq', 'need_prediction']\n",
        "\n",
        "expected = META + FEATURE_NAMES + TARGET_NAMES\n",
        "missing = [c for c in expected if c not in cols_valid]\n",
        "extra = [c for c in cols_valid if c not in expected]\n",
        "print('missing:', missing)\n",
        "print('extra:', extra[:20])\n",
        "print('n_expected:', len(expected))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0bcab9d",
      "metadata": {},
      "source": [
        "## 2) Efficient sampling by `seq_ix`\n",
        "Reading `train.parquet` fully is heavy. We sample sequences for EDA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cb898498",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200000, 37)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seq_ix</th>\n",
              "      <th>step_in_seq</th>\n",
              "      <th>need_prediction</th>\n",
              "      <th>p0</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>p3</th>\n",
              "      <th>p4</th>\n",
              "      <th>p5</th>\n",
              "      <th>p6</th>\n",
              "      <th>p7</th>\n",
              "      <th>p8</th>\n",
              "      <th>p9</th>\n",
              "      <th>p10</th>\n",
              "      <th>p11</th>\n",
              "      <th>v0</th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>v11</th>\n",
              "      <th>dp0</th>\n",
              "      <th>dp1</th>\n",
              "      <th>dp2</th>\n",
              "      <th>dp3</th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>t0</th>\n",
              "      <th>t1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9000</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.117708</td>\n",
              "      <td>-2.539876</td>\n",
              "      <td>0.865908</td>\n",
              "      <td>2.539824</td>\n",
              "      <td>0.195069</td>\n",
              "      <td>-0.388850</td>\n",
              "      <td>2.863662</td>\n",
              "      <td>-1.341095</td>\n",
              "      <td>-0.341310</td>\n",
              "      <td>-0.675745</td>\n",
              "      <td>0.936237</td>\n",
              "      <td>-2.150848</td>\n",
              "      <td>1.253170</td>\n",
              "      <td>0.243244</td>\n",
              "      <td>-0.503940</td>\n",
              "      <td>0.310363</td>\n",
              "      <td>-0.497458</td>\n",
              "      <td>1.007608</td>\n",
              "      <td>0.229339</td>\n",
              "      <td>-0.103903</td>\n",
              "      <td>0.380122</td>\n",
              "      <td>-0.239512</td>\n",
              "      <td>0.412430</td>\n",
              "      <td>0.884924</td>\n",
              "      <td>2.954185</td>\n",
              "      <td>-1.855904</td>\n",
              "      <td>-2.766229</td>\n",
              "      <td>-2.348309</td>\n",
              "      <td>-0.903301</td>\n",
              "      <td>-0.021329</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>-1.412236</td>\n",
              "      <td>-0.631168</td>\n",
              "      <td>0.118742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9001</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.090878</td>\n",
              "      <td>-3.094500</td>\n",
              "      <td>0.652700</td>\n",
              "      <td>1.376513</td>\n",
              "      <td>-0.161029</td>\n",
              "      <td>-0.784070</td>\n",
              "      <td>2.900021</td>\n",
              "      <td>-1.339903</td>\n",
              "      <td>-0.728494</td>\n",
              "      <td>-2.198898</td>\n",
              "      <td>0.615159</td>\n",
              "      <td>-1.115513</td>\n",
              "      <td>-0.052615</td>\n",
              "      <td>1.524788</td>\n",
              "      <td>-1.149008</td>\n",
              "      <td>1.170180</td>\n",
              "      <td>0.022003</td>\n",
              "      <td>0.609296</td>\n",
              "      <td>0.197429</td>\n",
              "      <td>0.236789</td>\n",
              "      <td>-0.103250</td>\n",
              "      <td>-0.136045</td>\n",
              "      <td>-0.141688</td>\n",
              "      <td>0.598122</td>\n",
              "      <td>-3.035405</td>\n",
              "      <td>2.640745</td>\n",
              "      <td>-1.921200</td>\n",
              "      <td>1.088156</td>\n",
              "      <td>0.016403</td>\n",
              "      <td>1.470615</td>\n",
              "      <td>0.006681</td>\n",
              "      <td>1.131744</td>\n",
              "      <td>-0.870247</td>\n",
              "      <td>-0.130298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9002</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.319615</td>\n",
              "      <td>-2.152394</td>\n",
              "      <td>0.554884</td>\n",
              "      <td>0.722125</td>\n",
              "      <td>-0.378345</td>\n",
              "      <td>-0.549079</td>\n",
              "      <td>2.417399</td>\n",
              "      <td>-0.777606</td>\n",
              "      <td>-0.396813</td>\n",
              "      <td>-1.982075</td>\n",
              "      <td>0.493136</td>\n",
              "      <td>-0.913419</td>\n",
              "      <td>1.017180</td>\n",
              "      <td>-0.092944</td>\n",
              "      <td>-0.829056</td>\n",
              "      <td>0.675957</td>\n",
              "      <td>-0.324589</td>\n",
              "      <td>-0.253601</td>\n",
              "      <td>0.330399</td>\n",
              "      <td>0.123095</td>\n",
              "      <td>0.063132</td>\n",
              "      <td>-0.207890</td>\n",
              "      <td>-0.063161</td>\n",
              "      <td>0.709121</td>\n",
              "      <td>-1.077189</td>\n",
              "      <td>-2.467422</td>\n",
              "      <td>1.896397</td>\n",
              "      <td>2.791004</td>\n",
              "      <td>0.578299</td>\n",
              "      <td>-0.647483</td>\n",
              "      <td>1.081489</td>\n",
              "      <td>-1.075911</td>\n",
              "      <td>-0.870247</td>\n",
              "      <td>-0.383323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9003</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1.942703</td>\n",
              "      <td>-1.761948</td>\n",
              "      <td>0.497809</td>\n",
              "      <td>0.795322</td>\n",
              "      <td>-0.280911</td>\n",
              "      <td>-0.387078</td>\n",
              "      <td>2.096521</td>\n",
              "      <td>-0.684763</td>\n",
              "      <td>-0.279923</td>\n",
              "      <td>-1.667612</td>\n",
              "      <td>0.498490</td>\n",
              "      <td>-1.014571</td>\n",
              "      <td>0.878778</td>\n",
              "      <td>0.074033</td>\n",
              "      <td>-0.125629</td>\n",
              "      <td>1.343816</td>\n",
              "      <td>-0.607333</td>\n",
              "      <td>-0.026493</td>\n",
              "      <td>0.330399</td>\n",
              "      <td>0.123095</td>\n",
              "      <td>0.063132</td>\n",
              "      <td>-0.207890</td>\n",
              "      <td>-0.063161</td>\n",
              "      <td>0.709121</td>\n",
              "      <td>0.348110</td>\n",
              "      <td>0.229904</td>\n",
              "      <td>1.271018</td>\n",
              "      <td>0.161909</td>\n",
              "      <td>-0.406079</td>\n",
              "      <td>0.350817</td>\n",
              "      <td>0.357496</td>\n",
              "      <td>0.110627</td>\n",
              "      <td>-1.042384</td>\n",
              "      <td>-0.520793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9004</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.013671</td>\n",
              "      <td>-0.905924</td>\n",
              "      <td>0.627235</td>\n",
              "      <td>0.899534</td>\n",
              "      <td>0.013801</td>\n",
              "      <td>-0.175278</td>\n",
              "      <td>2.033104</td>\n",
              "      <td>-0.692715</td>\n",
              "      <td>-0.091712</td>\n",
              "      <td>-0.772153</td>\n",
              "      <td>0.648724</td>\n",
              "      <td>-1.651703</td>\n",
              "      <td>0.284408</td>\n",
              "      <td>0.288048</td>\n",
              "      <td>-0.899680</td>\n",
              "      <td>0.608505</td>\n",
              "      <td>-0.399561</td>\n",
              "      <td>-0.500826</td>\n",
              "      <td>0.108677</td>\n",
              "      <td>-0.013624</td>\n",
              "      <td>0.125887</td>\n",
              "      <td>-0.202607</td>\n",
              "      <td>0.427784</td>\n",
              "      <td>0.788932</td>\n",
              "      <td>2.205490</td>\n",
              "      <td>-0.061804</td>\n",
              "      <td>-1.678060</td>\n",
              "      <td>-2.138276</td>\n",
              "      <td>-0.965420</td>\n",
              "      <td>0.193143</td>\n",
              "      <td>-0.427976</td>\n",
              "      <td>-1.097845</td>\n",
              "      <td>-0.717236</td>\n",
              "      <td>-0.295661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      seq_ix  step_in_seq  need_prediction        p0        p1        p2  \\\n",
              "9000       9            0                0  3.117708 -2.539876  0.865908   \n",
              "9001       9            1                0  3.090878 -3.094500  0.652700   \n",
              "9002       9            2                0  2.319615 -2.152394  0.554884   \n",
              "9003       9            3                0  1.942703 -1.761948  0.497809   \n",
              "9004       9            4                0  2.013671 -0.905924  0.627235   \n",
              "\n",
              "            p3        p4        p5        p6        p7        p8        p9  \\\n",
              "9000  2.539824  0.195069 -0.388850  2.863662 -1.341095 -0.341310 -0.675745   \n",
              "9001  1.376513 -0.161029 -0.784070  2.900021 -1.339903 -0.728494 -2.198898   \n",
              "9002  0.722125 -0.378345 -0.549079  2.417399 -0.777606 -0.396813 -1.982075   \n",
              "9003  0.795322 -0.280911 -0.387078  2.096521 -0.684763 -0.279923 -1.667612   \n",
              "9004  0.899534  0.013801 -0.175278  2.033104 -0.692715 -0.091712 -0.772153   \n",
              "\n",
              "           p10       p11        v0        v1        v2        v3        v4  \\\n",
              "9000  0.936237 -2.150848  1.253170  0.243244 -0.503940  0.310363 -0.497458   \n",
              "9001  0.615159 -1.115513 -0.052615  1.524788 -1.149008  1.170180  0.022003   \n",
              "9002  0.493136 -0.913419  1.017180 -0.092944 -0.829056  0.675957 -0.324589   \n",
              "9003  0.498490 -1.014571  0.878778  0.074033 -0.125629  1.343816 -0.607333   \n",
              "9004  0.648724 -1.651703  0.284408  0.288048 -0.899680  0.608505 -0.399561   \n",
              "\n",
              "            v5        v6        v7        v8        v9       v10       v11  \\\n",
              "9000  1.007608  0.229339 -0.103903  0.380122 -0.239512  0.412430  0.884924   \n",
              "9001  0.609296  0.197429  0.236789 -0.103250 -0.136045 -0.141688  0.598122   \n",
              "9002 -0.253601  0.330399  0.123095  0.063132 -0.207890 -0.063161  0.709121   \n",
              "9003 -0.026493  0.330399  0.123095  0.063132 -0.207890 -0.063161  0.709121   \n",
              "9004 -0.500826  0.108677 -0.013624  0.125887 -0.202607  0.427784  0.788932   \n",
              "\n",
              "           dp0       dp1       dp2       dp3       dv0       dv1       dv2  \\\n",
              "9000  2.954185 -1.855904 -2.766229 -2.348309 -0.903301 -0.021329  0.287012   \n",
              "9001 -3.035405  2.640745 -1.921200  1.088156  0.016403  1.470615  0.006681   \n",
              "9002 -1.077189 -2.467422  1.896397  2.791004  0.578299 -0.647483  1.081489   \n",
              "9003  0.348110  0.229904  1.271018  0.161909 -0.406079  0.350817  0.357496   \n",
              "9004  2.205490 -0.061804 -1.678060 -2.138276 -0.965420  0.193143 -0.427976   \n",
              "\n",
              "           dv3        t0        t1  \n",
              "9000 -1.412236 -0.631168  0.118742  \n",
              "9001  1.131744 -0.870247 -0.130298  \n",
              "9002 -1.075911 -0.870247 -0.383323  \n",
              "9003  0.110627 -1.042384 -0.520793  \n",
              "9004 -1.097845 -0.717236 -0.295661  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sample_sequences(path: Path, n_seq: int = 200, seed: int = 42):\n",
        "    # Cheap: read only seq_ix column from parquet\n",
        "    seq_col = pd.read_parquet(path, columns=['seq_ix'])\n",
        "    uniq = seq_col['seq_ix'].unique()\n",
        "    rng = np.random.default_rng(seed)\n",
        "    choice = rng.choice(uniq, size=min(n_seq, len(uniq)), replace=False)\n",
        "    return np.array(choice, dtype=np.int64)\n",
        "\n",
        "def load_by_seq(path: Path, seq_ix: np.ndarray, columns=None):\n",
        "    df = pd.read_parquet(path, columns=columns)\n",
        "    return df[df['seq_ix'].isin(seq_ix)].copy()\n",
        "\n",
        "seq_sample = sample_sequences(VALID_PATH, n_seq=200, seed=42)\n",
        "df = load_by_seq(VALID_PATH, seq_sample, columns=META + FEATURE_NAMES + TARGET_NAMES)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d873b69f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seq 9 rows 1000 step_min/max 0 999\n",
            "need_prediction true count: 901\n",
            "seq 32 rows 1000 step_min/max 0 999\n",
            "need_prediction true count: 901\n",
            "seq 42 rows 1000 step_min/max 0 999\n",
            "need_prediction true count: 901\n"
          ]
        }
      ],
      "source": [
        "# Sanity: sequences should be contiguous and step_in_seq should cover 0..999\n",
        "def sanity_sequences(df: pd.DataFrame, n_show: int = 3):\n",
        "    for s in df['seq_ix'].unique()[:n_show]:\n",
        "        sub = df[df['seq_ix'] == s]\n",
        "        print('seq', s, 'rows', len(sub), 'step_min/max', sub.step_in_seq.min(), sub.step_in_seq.max())\n",
        "        print('need_prediction true count:', sub.need_prediction.sum())\n",
        "\n",
        "sanity_sequences(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149c1f33",
      "metadata": {},
      "source": [
        "## 3) Target distribution + weighting intuition\n",
        "Metric weights samples by `abs(y)`, so the tail matters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7ae5eacc",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"None of [Index([0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n       ...\\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n      dtype='int8', length=200000)] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_scored = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneed_prediction\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mscored rows:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_scored))\n\u001b[32m      3\u001b[39m df_scored[TARGET_NAMES].describe().T\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/competitions/competition_package/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/competitions/competition_package/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/competitions/competition_package/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyError\u001b[39m: \"None of [Index([0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n       ...\\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n      dtype='int8', length=200000)] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "df_scored = df.loc[df['need_prediction'].astype(bool)].copy()\n",
        "print('scored rows:', len(df_scored))\n",
        "df_scored[TARGET_NAMES].describe().T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 7))\n",
        "for i, t in enumerate(TARGET_NAMES):\n",
        "    ax = axes[i, 0]\n",
        "    ax.hist(df_scored[t].values, bins=200)\n",
        "    ax.set_title(f'{t} distribution')\n",
        "\n",
        "    ax = axes[i, 1]\n",
        "    ax.hist(np.abs(df_scored[t].values), bins=200, log=True)\n",
        "    ax.set_title(f'abs({t}) (log-y)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Feature correlation with targets (quick baseline)\n",
        "We compute simple Pearson correlation featureâ†”target on scored rows.\n",
        "This is not the competition metric, but helps spot obviously useful features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_scored[FEATURE_NAMES].to_numpy(np.float32)\n",
        "Y = df_scored[TARGET_NAMES].to_numpy(np.float32)\n",
        "\n",
        "# Standardize features for stable corr\n",
        "Xz = (X - X.mean(axis=0, keepdims=True)) / (X.std(axis=0, keepdims=True) + 1e-6)\n",
        "\n",
        "corrs = {}\n",
        "for j, t in enumerate(TARGET_NAMES):\n",
        "    y = Y[:, j]\n",
        "    y = (y - y.mean()) / (y.std() + 1e-6)\n",
        "    c = (Xz * y[:, None]).mean(axis=0)\n",
        "    corrs[t] = c\n",
        "\n",
        "corr_df = pd.DataFrame({\n",
        "    'feature': FEATURE_NAMES,\n",
        "    'corr_t0': corrs['t0'],\n",
        "    'corr_t1': corrs['t1'],\n",
        "})\n",
        "corr_df['abs_sum'] = np.abs(corr_df['corr_t0']) + np.abs(corr_df['corr_t1'])\n",
        "corr_df.sort_values('abs_sum', ascending=False).head(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Autocorrelation within sequences\n",
        "We check how persistent targets (and some features) are over time.\n",
        "This helps to choose:\n",
        "- context length\n",
        "- EWMA alpha\n",
        "- whether diff features matter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_acf_by_seq(df: pd.DataFrame, col: str, max_lag: int = 50) -> np.ndarray:\n",
        "    # returns mean ACF[lag] averaged over sequences\n",
        "    acfs = []\n",
        "    for s, sub in df.groupby('seq_ix'):\n",
        "        sub = sub.sort_values('step_in_seq')\n",
        "        x = sub[col].to_numpy(np.float32)\n",
        "        x = x - x.mean()\n",
        "        denom = float((x * x).mean() + 1e-8)\n",
        "        a = [1.0]\n",
        "        for lag in range(1, max_lag + 1):\n",
        "            a.append(float((x[:-lag] * x[lag:]).mean() / denom))\n",
        "        acfs.append(a)\n",
        "    return np.mean(np.asarray(acfs), axis=0)\n",
        "\n",
        "max_lag = 60\n",
        "acf_t0 = mean_acf_by_seq(df_scored, 't0', max_lag=max_lag)\n",
        "acf_t1 = mean_acf_by_seq(df_scored, 't1', max_lag=max_lag)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(acf_t0, label='t0 ACF')\n",
        "plt.plot(acf_t1, label='t1 ACF')\n",
        "plt.axhline(0, color='black', linewidth=1)\n",
        "plt.title('Mean ACF across sampled sequences (scored steps only)')\n",
        "plt.xlabel('lag')\n",
        "plt.ylabel('corr')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Cross-correlation: feature(t) vs target(t+k)\n",
        "We approximate predictive horizon by checking corr(x_t, y_{t+lag}).\n",
        "This is not perfect, but often reveals whether very short lags dominate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_xcorr_feature_target(df: pd.DataFrame, feature: str, target: str, max_lag: int = 20) -> np.ndarray:\n",
        "    # corr(x_t, y_{t+lag}) averaged over sequences\n",
        "    out = []\n",
        "    for s, sub in df.groupby('seq_ix'):\n",
        "        sub = sub.sort_values('step_in_seq')\n",
        "        x = sub[feature].to_numpy(np.float32)\n",
        "        y = sub[target].to_numpy(np.float32)\n",
        "        x = (x - x.mean()) / (x.std() + 1e-6)\n",
        "        y = (y - y.mean()) / (y.std() + 1e-6)\n",
        "        c = [float((x * y).mean())]\n",
        "        for lag in range(1, max_lag + 1):\n",
        "            c.append(float((x[:-lag] * y[lag:]).mean()))\n",
        "        out.append(c)\n",
        "    return np.mean(np.asarray(out), axis=0)\n",
        "\n",
        "top_features = corr_df.sort_values('abs_sum', ascending=False).head(3)['feature'].tolist()\n",
        "print('top features by simple corr:', top_features)\n",
        "\n",
        "max_lag = 30\n",
        "fig, axes = plt.subplots(len(top_features), 2, figsize=(12, 3*len(top_features)), sharex=True)\n",
        "for i, f in enumerate(top_features):\n",
        "    for j, t in enumerate(TARGET_NAMES):\n",
        "        xcorr = mean_xcorr_feature_target(df_scored, f, t, max_lag=max_lag)\n",
        "        ax = axes[i, j] if len(top_features) > 1 else axes[j]\n",
        "        ax.plot(xcorr)\n",
        "        ax.axhline(0, color='black', linewidth=1)\n",
        "        ax.set_title(f'corr({f}_t, {t}_t+lag)')\n",
        "        ax.set_ylabel('corr')\n",
        "        ax.set_xlabel('lag')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Feature engineering sanity: diff + EWMA normalization\n",
        "We show how to compute the exact same engineered features we used in the GRU experiments:\n",
        "- `diff = x_t - x_{t-1}`\n",
        "- EWMA mean/var and normalized residual\n",
        "\n",
        "This helps you debug feature generation and see why it can help.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.lib_features import build_features_np\n",
        "\n",
        "seq0 = df[df.seq_ix == df.seq_ix.unique()[0]].sort_values('step_in_seq')\n",
        "x_seq = seq0[FEATURE_NAMES].to_numpy(np.float32)[None, :, :]\n",
        "\n",
        "f_raw = build_features_np(x_seq, use_diff=False, use_ewma=False)\n",
        "f_diff = build_features_np(x_seq, use_diff=True, use_ewma=False)\n",
        "f_ewma = build_features_np(x_seq, use_diff=False, use_ewma=True, ewma_alpha=0.05)\n",
        "f_both = build_features_np(x_seq, use_diff=True, use_ewma=True, ewma_alpha=0.05)\n",
        "\n",
        "print('raw shape:', f_raw.shape)\n",
        "print('diff shape:', f_diff.shape)\n",
        "print('ewma shape:', f_ewma.shape)\n",
        "print('both shape:', f_both.shape)\n",
        "\n",
        "# Plot one feature and its ewma-normalized version to see the effect\n",
        "k = 0\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(x_seq[0, :, k], label=f'raw {FEATURE_NAMES[k]}')\n",
        "plt.plot(f_ewma[0, :, 32 + k], label=f'ewma_norm {FEATURE_NAMES[k]}')\n",
        "plt.legend()\n",
        "plt.title('Example: raw feature vs EWMA-normalized feature')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "competition-package",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
